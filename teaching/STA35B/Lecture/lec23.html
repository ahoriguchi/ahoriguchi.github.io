<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Inference for linear regression</title>
    <meta charset="utf-8" />
    <meta name="author" content="Akira Horiguchi   Figures taken from [IMS], Cetinkaya-Rundel and Hardin text" />
    <script src="lec23_files/header-attrs-2.29/header-attrs.js"></script>
    <script src="lec23_files/kePrint-0.0.1/kePrint.js"></script>
    <link href="lec23_files/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Inference for linear regression
]
.subtitle[
## <br><br> STA35B: Statistical Data Science 2
]
.author[
### Akira Horiguchi <br> Figures taken from [IMS], Cetinkaya-Rundel and Hardin text
]

---

  


  


.pull-left[
### Inference for linear regression with a single variable 

* We'll consider chain sandwich stores that spent different amounts on advertising and then the amount of revenue they received
* Suppose data, **for all** chain sandwich stores and amount spent on advertising, looked like: 


&lt;img src="lec23_files/figure-html/unnamed-chunk-1-1.png" width="100%" style="display: block; margin: auto;" /&gt;

]

--

.pull-right[


The population model is: `$$y = \beta_0 + \beta_1 x + \varepsilon.$$`

Using all data in the true population, model would be:

&lt;!-- ```{r} --&gt;
&lt;!-- lm(rev ~ ad, data=sandwich) |&gt; tidy() --&gt;
&lt;!-- ``` --&gt;

`$$\texttt{expected revenue} = 11.23 + 4.9 \times \texttt{advertising}.$$`
* (Can use `lm()` to compute these coefficients.)
* For every \$1,000 spent on advertising, revenue increases by \$4,900 on average
* If we spent nothing on advertising, we expect \$11,230 revenue on average 

However, it's often too time-consuming or expensive to get data from the **entire** population.

* More realistic to have/collect data from only a **subset** of the population.
* **Goal**: use subset to **infer** population's slope and intercept.
]

&lt;!-- --- --&gt;

&lt;!-- .pull-left[ --&gt;
&lt;!-- Different subsets lead to different lines of best fit. --&gt;

&lt;!-- * Let's took at two different subsets of 20 stores. --&gt;


&lt;!-- ```{r} --&gt;
&lt;!-- #| echo: false --&gt;
&lt;!-- set.seed(470) --&gt;
&lt;!-- sandwich2 &lt;- sandwich %&gt;% --&gt;
&lt;!--   sample_n(size = 20) --&gt;
&lt;!-- sandwich3 &lt;- sandwich %&gt;% --&gt;
&lt;!--   sample_n(size = 20) --&gt;
&lt;!-- sandwich_many &lt;- sandwich %&gt;% --&gt;
&lt;!--   rep_sample_n(size = 20, replace = FALSE, reps = 50) --&gt;
&lt;!-- ``` --&gt;

&lt;!-- ```{r} --&gt;
&lt;!-- #| label: fig-sand-samp1 --&gt;
&lt;!-- #| echo: false --&gt;
&lt;!-- #| message: false --&gt;
&lt;!-- #| warning: false --&gt;
&lt;!-- #| fig.align: center --&gt;
&lt;!-- #| out.width: 100% --&gt;

&lt;!-- sandwich_many |&gt;  --&gt;
&lt;!--     filter(replicate %in% c(1, 4)) |&gt; --&gt;
&lt;!--     mutate(subset = as.factor(replicate)) |&gt;  --&gt;
&lt;!--   ggplot(aes(ad, rev, color=subset, shape=subset)) + --&gt;
&lt;!--   geom_point(size = 3) + --&gt;
&lt;!--   geom_smooth(method = "lm", se = FALSE, fullrange = TRUE) + --&gt;
&lt;!--   scale_x_continuous(labels = label_dollar(suffix = "K")) + --&gt;
&lt;!--   scale_y_continuous(labels = label_dollar(suffix = "K")) + --&gt;
&lt;!--   labs( --&gt;
&lt;!--     x = "Amount spent on advertising", --&gt;
&lt;!--     y = "Revenue", --&gt;
&lt;!--     title = "Chain sandwich store" --&gt;
&lt;!--     # subtitle = "Random sample of 20 stores" --&gt;
&lt;!--   ) + --&gt;
&lt;!--   facet_wrap(subset~., nrow=1, labeller="label_both") + --&gt;
&lt;!--   coord_cartesian(ylim = c(0, 65)) +  --&gt;
&lt;!--   theme_bw() +  --&gt;
&lt;!--   theme(legend.position = "none") --&gt;
&lt;!-- ``` --&gt;


&lt;!-- ] --&gt;

&lt;!-- -- --&gt;

&lt;!-- .pull-right[ --&gt;

&lt;!-- If we did this on many different samples of 20 stores, we would get varied lines: --&gt;


&lt;!-- ```{r} --&gt;
&lt;!-- #| label: fig-slopes --&gt;
&lt;!-- #| echo: false --&gt;
&lt;!-- #| warning: false --&gt;
&lt;!-- #| message: false --&gt;
&lt;!-- #| out.width: 100% --&gt;

&lt;!-- ggplot() + --&gt;
&lt;!--   geom_smooth( --&gt;
&lt;!--     data = sandwich_many, aes(x = ad, y = rev, group = replicate), --&gt;
&lt;!--     method = "lm", se = FALSE, fullrange = TRUE,  --&gt;
&lt;!--     color = IMSCOL["gray", "f2"], size = 0.5 --&gt;
&lt;!--   ) + --&gt;
&lt;!--   geom_smooth( --&gt;
&lt;!--     data = sandwich, aes(x = ad, y = rev), method = "lm", se = FALSE, --&gt;
&lt;!--     fullrange = TRUE, color = IMSCOL["red", "full"] --&gt;
&lt;!--   ) + --&gt;
&lt;!--   scale_x_continuous(labels = label_dollar(suffix = "K"), breaks=seq(0, 10, by=1)) + --&gt;
&lt;!--   scale_y_continuous(labels = label_dollar(suffix = "K")) + --&gt;
&lt;!--   labs( --&gt;
&lt;!--     x = "Amount spent on advertising", --&gt;
&lt;!--     y = "Revenue", --&gt;
&lt;!--     title = "Chain sandwich store", --&gt;
&lt;!--     subtitle = "Many random samples of 20 stores" --&gt;
&lt;!--   ) + --&gt;
&lt;!--   coord_cartesian(ylim = c(0, 65)) +  --&gt;
&lt;!--     theme_bw() --&gt;
&lt;!-- ``` --&gt;
&lt;!-- ] --&gt;

---
.pull-left[
* The relevant hypotheses for a linear model are about whether or not the population slope parameter is zero.
  - `\(H_0\)`: `\(\beta_1 = 0\)`, no linear relationship between response and independent variable
  - `\(H_A\)`: `\(\beta_1 \neq 0\)`, some linear relationship between response and independent variable

* We can perform similar analyses that we used before:
  - Randomization test
  - Bootstrap confidence interval
  - Mathematical approach

]

--

.pull-right[
#### Randomization test
* A randomization test randomly permutes the responses in order to destroy any relationship between the response and independent variable.
* This provides a sense of the variability we should expect under null hypothesis.

E.g. consider **births14** dataset as before, which has baby birth weight and number of weeks of gestation


&lt;img src="lec23_files/figure-html/fig-permweightScatter-1.png" width="100%" /&gt;
]

---

.pull-left[
* Each permutation produces a line of best fit.

&lt;img src="lec23_files/figure-html/fig-permweekslm-1.png" width="100%" /&gt;

* By doing this for many permutations,&lt;br&gt; we see what slope values we would get when there is no relationship between the response and the independent variable.

]

--

.pull-right[

Do this for 10,000 permutations.

&lt;img src="lec23_files/figure-html/fig-nulldistBirths-1.png" width="432" style="display: block; margin: auto;" /&gt;


* If there were no linear relationship between `weight` and `weeks`, the natural variability of the slopes would produce estimates between approximately -0.15 and +0.15.
* We reject the null hypothesis:&lt;br&gt; we believe that the slope observed on the original data is not just due to natural variability.&lt;br&gt; Rather, we believe there is a linear relationship between baby `weight` and `weeks` of gestation.

]

---

.pull-left[
#### Bootstrap for confidence interval for the slope
Now look at predicting a baby's weight using the mother's age.

* When we run the following code, we get

``` r
lm(weight ~ mage, data=births14_100) |&gt; tidy()
```




&lt;table class="table table-striped table-condensed" style="color: black; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;width: 10em; font-family: monospace;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;width: 5em; "&gt; 7.34 &lt;/td&gt;
   &lt;td style="text-align:right;width: 5em; "&gt; 0.60 &lt;/td&gt;
   &lt;td style="text-align:right;width: 5em; "&gt; 12.29 &lt;/td&gt;
   &lt;td style="text-align:right;width: 5em; "&gt; &amp;lt;0.0001 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;width: 10em; font-family: monospace;"&gt; mage &lt;/td&gt;
   &lt;td style="text-align:right;width: 5em; "&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:right;width: 5em; "&gt; 0.02 &lt;/td&gt;
   &lt;td style="text-align:right;width: 5em; "&gt; -0.11 &lt;/td&gt;
   &lt;td style="text-align:right;width: 5em; "&gt; 0.915 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;



* We will take bootstrap samples of the original data.
* Sampling with replacement `\(\Rightarrow\)` &lt;br&gt; a bootstrap sample might end up having **multiple** instances of a data point from original dataset, or **one** instance of that data point, or **no** instances.
    * See overlapping points in plots on right.

&lt;!-- * We will sometimes get the same sample in the resulting bootstrap, sometimes will not, sometimes get it twice --&gt;
]

--

.pull-right[


``` r
births14_100 |&gt; n_distinct()
#&gt; [1] 100
```


&lt;img src="lec23_files/figure-html/fig-birth2BS-1.png" width="80%" style="display: block; margin: auto;" /&gt;&lt;img src="lec23_files/figure-html/fig-birth2BS-2.png" width="80%" style="display: block; margin: auto;" /&gt;

]

---

.pull-left[
* For each bootstrap sample, we compute a linear model on the data
* We then plot a histogram of all of the different slopes we get
* This gives us a sense of the variability of the slopes across random samples

&lt;img src="lec23_files/figure-html/fig-mageBSslopes-1.png" width="100%" style="display: block; margin: auto;" /&gt;

]

--

.pull-right[

Suppose all of the bootstrap slopes are given in the vector `slopes`

* The following code calculating the end points for the bootstrap 95% confidence interval.
    
    ``` r
    quantile(x, probs = c(0.025, 0.975))
    ```

From this we state:&lt;br&gt; we are 95% confident that, for the model of weight of a baby described by mother's age, a one unit increase in mother's age will be associated with an increase in predicted average baby weight of between -0.01 and 0.081 pounds
* This includes 0, so it is possible mother's age does not have meaningful linear relationship with baby's weight 
]


---

.pull-left[
### Mathematical model for testing a slope
* Under certain conditions, can use the `\(t\)`-distribution to test and estimate the slope parameter in linear regression.  Conditions:

-   **Linearity.** The data should show a linear trend.

-   **Independent observations.** Be cautious about applying regression to data that are sequential observations in time, e.g. stock prices/day

-   **Nearly normal residuals.** Generally, the residuals should be nearly normal.   When this condition is found to be unreasonable, it is often because of outliers or concerns about influential points
    
-   **Constant or equal variability.** The variability of points around the least squares line remains roughly constant.


]

--

.pull-right[

Four examples below: do they satisfy the conditions?

&lt;img src="lec23_files/figure-html/unnamed-chunk-12-1.png" width="100%" /&gt;


]

---

.pull-left[
### Example
Dataset `openintro::midterms_house` has info on US elections, with unemployment rate and election outcomes in **midterm** elections

* Question: does higher unmployment rate entail worse performance for the current President's party?


```
#&gt; tibble [31 Ã— 5] (S3: tbl_df/tbl/data.frame)
#&gt;  $ year        : int [1:31] 1899 1903 1907 1911 1915 1919 1923 1927 1931 1935 ...
#&gt;  $ potus       : Factor w/ 19 levels "Barack Obama",..: 18 16 16 17 19 19 3 3 11 6 ...
#&gt;  $ party       : Factor w/ 2 levels "Democrat","Republican": 2 2 2 2 1 1 2 2 2 1 ...
#&gt;  $ unemp       : num [1:31] 11.62 4.3 3.29 5.86 6.63 ...
#&gt;  $ house_change: num [1:31] -9.22 -4.28 -12.29 -26.59 -20.96 ...
```

]

--

.pull-right[

``` r
midterms_house |&gt;
  ggplot(aes(unemp, house_change)) +
  geom_text(aes(label=substr(party, 1, 1), 
                color=party, shape=party), size=5) +
  labs(x = "Percent unemployed", y = "Percent change in House seats\nfor the President's party") +
  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1), limits = c(3.5, 12.1), breaks = seq(0, 100, by=2)) +
  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1), limits = c(-31, 11), breaks = c(-30, -20, -10, 0, 10)) +
  scale_color_manual(
      values = c("Republican" = "red", 
                 "Democrat" = "blue")) +
  theme(legend.position = c(0.8, 0.8))
```

&lt;img src="lec23_files/figure-html/fig-unemploymentAndChangeInHouse-1.png" width="100%" style="display: block; margin: auto;" /&gt;

]

&lt;!-- geom_point(aes(color=party, shape=party), size = 3, alpha = 0.7) + --&gt;

---

Let's build a linear model for the change in house seats for a president's party as a function of unemployment rate

* Let's restrict to election years OUTSIDE of the Great Depression (i.e., not year 1935 or 1939)
    
    ``` r
    not_gd_data &lt;- midterms_house |&gt; filter(! ( year %in% c(1935, 1939)))
    ```
* First check that there are no substantial outliers, no clear nonlinearity

.pull-left[

&lt;img src="lec23_files/figure-html/unnamed-chunk-16-1.png" width="432" style="display: block; margin: auto;" /&gt;
* Let's now compute and examine residuals (right).

]

.pull-right[
&lt;img src="lec23_files/figure-html/unnamed-chunk-17-1.png" width="432" style="display: block; margin: auto;" /&gt;
* No clear problems with the residuals
* Does appear the linear model might not be the best fit, but let's investigate 
]
---

.pull-left[

Recall question: does higher unmployment rate entail worse performance for the current President's party?

We can frame this as hypothesis test:

- `\(H_0:\ \beta_1 = 0\)`, true linear model has slope zero
- `\(H_A:\ \beta_1 \neq 0\)`, true linear model has slope different than zero; unmployment rate is predcitve of change in seats after midterm election

To reject the null, we use the following test statistic

`$$T = \frac{\text{estimate} - \text{null}}{SE},$$`
which follows a `\(t\)` distribution with `\(n-2\)` degrees of freedom.  The 2 comes from the linear model having two parameters: `\(\beta_0\)`, intercept, and `\(\beta_1\)`, slope.  

* This course will not teach how to compute SE - just use the R table output.
* Let's build the linear model

]

--

.pull-right[ 

``` r
lm(house_change~unemp, data=not_gd_data) |&gt; tidy() |&gt; kable(digits=c(0, 3, 3, 3, 3))
```



|term        | estimate| std.error| statistic| p.value|
|:-----------|--------:|---------:|---------:|-------:|
|(Intercept) |   -7.364|     5.155|    -1.429|   0.165|
|unemp       |   -0.890|     0.835|    -1.066|   0.296|


* From this we see the following predictive model:

$$
`\begin{aligned}
&amp;\texttt{Percent change House seats for Pres's party}  \newline \\
&amp;\qquad\qquad= -7.36 - 0.89 \times \texttt{(unemployment rate)}
\end{aligned}`
$$
* Predicts greater unemployment rate implies worse performance in House midterm election
* Is there significant evidence that the "true" linear model has a negative slope?
* `\(T = \frac{-0.890-0}{0.835 } = -1.066\)` matches table output.
* We are testing two-sided alternative `\((\beta_1 \neq 0)\)`,&lt;br&gt; so p-value is (left-side area + right-side area):

``` r
2 * pt(-1.066, df = nrow(not_gd_data) - 2)
#&gt; [1] 0.2958637
```
]

&lt;!-- --- --&gt;

&lt;!-- .pull-left[ --&gt;

&lt;!-- ] --&gt;

&lt;!-- -- --&gt;

&lt;!-- .pull-right[ --&gt;

&lt;!-- ] --&gt;


---
### Practice 
* IMS 22.12(a,b)
* IMS 22.13(a,b)
* IMS 24.3(a,b)

* Take 3 minutes to think about the problem, discuss with your neighbors
* I'll call on one of you and ask what your thoughts are for how to approach the problem
* Not expecting you to have the right answer!  Just want to hear how you approach the problem, then help guide you through thinking about the next steps!
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>

<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Inference for comparing many means</title>
    <meta charset="utf-8" />
    <meta name="author" content="Akira Horiguchi   Figures taken from [IMS], Cetinkaya-Rundel and Hardin text" />
    <script src="lec22_files/header-attrs-2.29/header-attrs.js"></script>
    <script src="lec22_files/kePrint-0.0.1/kePrint.js"></script>
    <link href="lec22_files/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Inference for comparing many means
]
.subtitle[
## <br><br> STA35B: Statistical Data Science 2
]
.author[
### Akira Horiguchi <br> Figures taken from [IMS], Cetinkaya-Rundel and Hardin text
]

---

  

.pull-left[
### Based on Ch 22 of IMS

* We saw last class how to compare population means of two different populations 
* Suppose we want to compare means across many populations (e.g., SAT scores by city)
* Can imagine doing all pairwise comparisons:&lt;br&gt; LA vs SF, SF vs San Jose, Davis vs San Jose, ... 
* However, as we do more and more comparisons, likely that we will see differences in data that are solely due to random chance
* This is the goal of the **analysis of variance** (ANOVA) technique which we will talk about today
]

--

.pull-right[
ANOVA uses a *single* hypothesis test to check whether means across many groups are equal.  If `\(k\)` groups,

-   `\(H_0\)`: All `\(k\)` groups share the same mean outcome: `$$\mu_1 = \mu_2 = \cdots = \mu_k$$` where `\(\mu_j\)` represents the mean of the outcome for observations in group `\(j.\)`
-   `\(H_A\)`: At least one mean is different.

Must check three conditions on the data before performing ANOVA:

-   the observations are independent within and between groups,
-   the responses within each group are nearly normal, and
-   the variability across the groups is about equal.
]

---

.pull-left[
### Example
College departments often run multiple sections of the same intro course each semester due to high demand.

* Consider three sections of an intro stats course.
* Are there substantial differences in first exam scores in these three sections (A, B, and C)?
* Describe appropriate hypotheses to determine if there are any differences between the three sections.

]

--
.pull-right[
The hypotheses may be written in the following form:

-   `\(H_0\)`: The average score is identical in all sections, `$$\mu_A = \mu_B = \mu_C.$$` Assuming each section is equally difficult, the observed difference in exam scores is due to chance.
-   `\(H_A\)`: The average score varies by class. We would reject the null hypothesis in favor of the alternative hypothesis if there were larger differences among the class averages than what we might expect from chance alone.


In ANOVA, strong evidence favoring the alternative hypothesis typically comes from unusually large differences in the group means.

* Key to assessing this: look at how much the means differ relative to the variability of individual observations within each group.
    &lt;!-- * Within-group variability vs&lt;br&gt; between-group variability --&gt;
]

---

.pull-left[
Look at data below; does it look like the differences in group means could come from random chance? 

* Compare I vs II vs III, then compare IV vs V vs VI

&lt;!-- ```{r} --&gt;
&lt;!-- #| label: fig-toyANOVA --&gt;
&lt;!-- #| echo: false --&gt;
&lt;!-- #| fig.align: "center" --&gt;
&lt;!-- toy_anova |&gt; --&gt;
&lt;!--   mutate(group2 = if_else(group %in% c("I", "II", "III"), "Dataset 1", "Dataset 2")) |&gt; --&gt;
&lt;!--   ggplot(aes(x = group, y = outcome, color = group2, shape = group2)) + --&gt;
&lt;!--   geom_point(alpha = 0.7, size = 2, show.legend = FALSE) + --&gt;
&lt;!--   scale_color_openintro() + --&gt;
&lt;!--   scale_y_continuous(breaks=seq(-10, 10, by=2)) + --&gt;
&lt;!--   facet_wrap(~group2, nrow = 1, scales = "free_x") + --&gt;
&lt;!--   labs(x = "Group", y = "Outcome") + --&gt;
&lt;!--   theme(strip.text = element_text(size=20), axis.text = element_text(size=16), axis.title=element_text(size=20)) --&gt;
&lt;!-- ``` --&gt;

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="lec22_files/figure-html/fig-toyANOVA-1.png" alt="Data shown as points. Crosses indicate group means." width="432" /&gt;
&lt;p class="caption"&gt;Data shown as points. Crosses indicate group means.&lt;/p&gt;
&lt;/div&gt;

- group I has same center as group IV;&lt;br&gt; group II has same center as group V;&lt;br&gt; group III has same center as group VI.
]

--

.pull-right[

Consider the ratio
`$$\frac{\text{between-group variability}}{\text{within-group variability}}$$`

- What does this look like for Groups I/II/III?&lt;br&gt; For groups IV/V/VI?
- What does a **large** ratio value suggest?&lt;br&gt; What does a **small** ratio value suggest? 

----------------------

.pull-left[
Groups I/II/III:&lt;br&gt; it is plausible that difference in group centers is due to random chance.
]

.pull-right[
Groups IV/V/VI: difference in group centers seem large relative to variability within each group, possibly due to true differences across groups.
]

]

---

.pull-left[
#### F statistic

**Goal**: assess whether the observed variability in sample group means is due to random chance

For between-group variability, consider the&lt;br&gt; **sum of squares between groups (SSG)**:

`$$SSG = \sum_{j=1}^k n_j (\bar x_j - \bar x)^2$$`

- `\(k\)` is the number of means we are comparing;
- `\(n_j\)` is the number of observations in group `\(j\)`; 
- `\(\bar x_j\)` is the sample mean of group `\(j\)`;
- `\(\bar x\)` is the overall sample mean across *all* observations.

For within-group variability, consider the&lt;br&gt; **sum of squares errors (SSE)**:

`$$\begin{align*}SSE&amp;= \sum_{j=1}^k \sum_{i=1}^{n_j} ( x_{j,i} - \bar x_j)^2\end{align*}$$`

&lt;!-- Will use for comparing *many* means --&gt;

&lt;!-- * **Goal**: assess whether the observed variability in sample group means is large enough to be unlikely due to random chance --&gt;
&lt;!-- * **Approach**: compare the **sum of squares between groups (SSG)** to the **sum of squared errors (SSE)**: --&gt;

&lt;!-- `$$SSG = \sum_{j=1}^k n_j (\bar x_j - \bar x)^2$$` --&gt;

&lt;!-- - `\(k\)` is the number of means we are comparing; --&gt;
&lt;!-- - `\(n_j\)` is the number of observations in group `\(j\)`;  --&gt;
&lt;!-- - `\(\bar x_j\)` is the sample mean of group `\(j\)`; --&gt;
&lt;!-- - `\(\bar x\)` is the overall sample mean across *all* observations. --&gt;

&lt;!-- `$$\begin{align*}SSE&amp;= \sum_{i=1}^n ( x_i - \bar x)^2\end{align*}$$` --&gt;

]

.pull-right[

SSG: variability of group means (weighted by group size)
&lt;img src="lec22_files/figure-html/unnamed-chunk-2-1.png" width="396" style="display: block; margin: auto;" /&gt;


SSE: variability within each group

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="lec22_files/figure-html/unnamed-chunk-3-1.png" alt="Data shown as points. Crosses indicate group means." width="396" /&gt;
&lt;p class="caption"&gt;Data shown as points. Crosses indicate group means.&lt;/p&gt;
&lt;/div&gt;

&lt;!-- SSE: variability among all observations --&gt;
&lt;!-- ```{r} --&gt;
&lt;!-- #| echo: false --&gt;
&lt;!-- #| warning: false --&gt;
&lt;!-- #| fig.width: 6 --&gt;
&lt;!-- #| fig.align: "center" --&gt;

&lt;!-- toy_anova |&gt; --&gt;
&lt;!--   mutate(group2 = if_else(group %in% c("I", "II", "III"), "Dataset 1", "Dataset 2")) |&gt; --&gt;
&lt;!--   ggplot(aes(x = group2, y = outcome, color = group2, shape = group2)) + --&gt;
&lt;!--   geom_point(alpha = 0.7, size = 2, show.legend = FALSE) + --&gt;
&lt;!--   geom_hline(data=dmeans, aes(yintercept = dmean, color = group2), size = 1.5, linetype="dashed", show.legend = FALSE) + --&gt;
&lt;!--   scale_color_openintro() + --&gt;
&lt;!--   scale_y_continuous(breaks=seq(-10, 10, by=2)) + --&gt;
&lt;!--   facet_wrap(~group2, nrow = 1, scales = "free_x") + --&gt;
&lt;!--   labs(x = NULL, y = "Outcome") + --&gt;
&lt;!--   theme(strip.text = element_text(size=20), axis.text = element_text(size=16), axis.title=element_text(size=20)) --&gt;
&lt;!-- ``` --&gt;
]

---

.pull-left[
#### F statistic

It turns out that the **sum of squares total (SST)**
`$$SST = \sum_{i=1}^n (x_i - \bar x)^2$$`
is the sum of SSG and SSE:
`$$SST = SSG + SSE$$`
which can be shown using a bunch of algebra.

(Note: I am using the textbook's abbreviations for SSG, SSE, and SST. For this course, I would like you to do the same. But other texts may use different abbreviations, such as total sum of squares (TSS), and SST might refer to sum of squares for treatment, which is our SSG. Therefore, it is very important that you understand what each abbreviation means and the intuition behind them, and not just memorize the abbreviations.)

&lt;!-- For between-group variability, consider the&lt;br&gt; **sum of squares between groups (SSG)**: --&gt;

&lt;!-- `$$SSG = \sum_{j=1}^k n_j (\bar x_j - \bar x)^2$$` --&gt;

&lt;!-- - `\(k\)` is the number of means we are comparing; --&gt;
&lt;!-- - `\(n_j\)` is the number of observations in group `\(j\)`;  --&gt;
&lt;!-- - `\(\bar x_j\)` is the sample mean of group `\(j\)`; --&gt;
&lt;!-- - `\(\bar x\)` is the overall sample mean across *all* observations. --&gt;

&lt;!-- For within-group variability, consider the&lt;br&gt; **sum of squares errors (SSE)**: --&gt;

&lt;!-- `$$\begin{align*}SSE&amp;= \sum_{j=1}^k \sum_{i=1}^{n_j} ( x_{j,i} - \bar x_j)^2\end{align*}$$` --&gt;

]
--
.pull-right[
&lt;!-- * Compare SSG to the total variability of all samples to the total mean across all samples using **sum of squared errors (SSE)** --&gt;

&lt;!-- `$$\begin{align*}SSE&amp;= \sum_{i=1}^n ( x_i - \bar x)^2\end{align*}$$` --&gt;

For reasons we'll see later, we'll want to use *scaled* versions of SSG and SSE:

* The **mean square between groups (MSG)** is a scaled version of SSG; &lt;br&gt; the **mean squared errors (MSE)** is a scaled version of SSE:

`$$\begin{align*} MSG &amp;= \frac{1}{\mathsf{df}_G} SSG = \frac{1}{k-1} SSG,\newline MSE&amp;=\frac{1}{\mathsf{df}_E} SSE =\frac{1}{n-k} SSE.\end{align*}$$`

The **F statistic** is defined to be ratio of these two:
`$$F = \frac{MSG}{MSE}.$$`

- Typically use software to compute. Not worth doing by hand.

Let's now do a randomization test using this F statistic to see if the differences in means are likely due to random chance or not.

&lt;!-- * Under null hypothesis that all means are the same, and under the three conditions, the statistic `\(F\)` follows an "F distribution" (see next slide). --&gt;
]

---



.pull-left[
#### Example: class data
&lt;!-- Recall the exams data which demonstrated a two-sample randomization test for a comparison of means. --&gt;

A teacher gave three versions (A, B, C) of an exam.

* Data is summarized in table/plot to the right.
* Is the exam difficulty the same across the three versions?

Hypothesis test:

-   `\(H_0\)`: All three versions are equally difficult. `$$\mu_A = \mu_B = \mu_C$$`
-   `\(H_A\)`: not `\(H_0.\)` At least one version is inherently more (or less) difficult than the others.

]

.pull-right[
&lt;table class="table table-striped table-condensed" style="color: black; width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Version &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; n &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Mean &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; SD &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Min &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Max &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;width: 5em; "&gt; A &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 58 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 75.1 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 13.9 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 44 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 100 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;width: 5em; "&gt; B &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 55 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 72.0 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 13.8 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 38 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 100 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;width: 5em; "&gt; C &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 51 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 78.9 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 13.1 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 45 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 100 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;



&lt;img src="lec22_files/figure-html/fig-boxplotThreeVersionsOfExams-1.png" width="432" style="display: block; margin: auto;" /&gt;

]


---

.pull-left[
Randomization test with *many* means: 

- Idea is the same as in *two* means.
- Null assumption: versions are equally difficult.
- Exam version (A or B or C) is randomly allocated to the exam scores, under the null assumption.

&lt;img src="randANOVA.png" width="100%" /&gt;

- For each simulation, we calculate the F statistic.

]

.pull-right[

&lt;!-- Since the groups are randomized, the population means under the randomization are the same, so we can see the types of outcomes that result from pure random sampling --&gt;

&lt;img src="lec22_files/figure-html/fig-rand3exams-1.png" width="90%" style="display: block; margin: auto;" /&gt;
- 297 of 10,000 simulations had an F statistic greater than or equal to the observed value 3.48.
- p-value 0.0297 is below 0.05, so we reject `\(H_0\)`.
- Conclusion: our observed value is unlikely due to chance if null assumption is true.

&lt;!-- - Randomization test p-value is then 0.0297 --&gt;
&lt;!-- * Our data's observed test statistic had `\(F = 3.48\)` --&gt;
&lt;!-- * We see this is quite unlikely due to chance - in this randomization test, fewer than 3% of instances where means are equal produce this (or more) extreme of a value. --&gt;
]

---

### Test statistic for three or more means is an F

.pull-left[ 
Recall: the **F statistic** is a ratio of how the groups differ (MSG) as compared to how the observations within a group vary (MSE).

`$$F = \frac{MSG}{MSE}$$`

When the null hypothesis is true and the conditions below are met, the F statistic follows an **F distribution** with parameters `\(df_1 = k-1\)` and `\(df_2 = n-k.\)`

Conditions:

- the observations are independent within and between groups,
- the responses within each group are nearly normal, and
- the variability across the groups is about equal.

&lt;!-- Conditions (XX double check): --&gt;

&lt;!-- -   independent observations, both within and across groups, --&gt;
&lt;!-- -   large samples and no extreme outliers --&gt;


&lt;!-- Under null hypothesis that all means are equal and under conditions of (1) independence, (2) approximately normal (large sample size, no extreme outliers), and (3) nearly the same variance across groups, we know that --&gt;

&lt;!-- $$ F = \frac{MSG}{MSE} \text{ has `\(F(df=n_1-1, df=n_2-1)\)` distribution}$$ --&gt;
]

.pull-right[
* F distribution is determined by two parameters, `\(df_1\)` and `\(df_2\)`, representing degrees of freedom
* F distribution in general does NOT look like t distribution or normal distribution - it is always non-negative, so cannot be something which can take negative values
&lt;img src="F.png" width="85%" /&gt;

]


---

.pull-left[ 
#### Mathematical model, test for comparing 3+ means

Why do we care about the F-distribution?

* It allows us to use a mathematical approach to evaluate null hypothesis 

* The `\(p\)`-value for the problem is given by the area under the F-distribution curve to the right of the observed F-statistic value.

    * Also known as the "right-tail area"

* Similar functions in R can be used to calculate percentiles and areas for F statistics
  - `pnorm()`, `pt()`, `pf()` - percent of data to the left of a certain value
  - `qnorm()`, `qt()`, `qf()` - value corresponding to data at a certain percentile
]
--
.pull-right[
### Examples: Exams

* So if we return to the data here
&lt;table class="table table-striped table-condensed" style="color: black; width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Version &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; n &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Mean &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; SD &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Min &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Max &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;width: 5em; "&gt; A &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 58 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 75.1 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 13.9 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 44 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 100 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;width: 5em; "&gt; B &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 55 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 72.0 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 13.8 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 38 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 100 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;width: 5em; "&gt; C &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 51 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 78.9 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 13.1 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 45 &lt;/td&gt;
   &lt;td style="text-align:center;width: 5em; "&gt; 100 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;



* The F statistic for this data was 3.48

* Mathematical approach for calculating `\(p\)`-value:
    
    ``` r
    df1 &lt;- 3 - 1  # k-1
    df2 &lt;- 58+55+51 - 3  # n-k
    pf(3.48, df1 = df1, df2 = df2)
    #&gt; [1] 0.9668556
    ```
* Only 3.3% of data is to the right of 3.48 
* `\(p\)`-value of 0.033 &lt; 0.05 - can reject the null hypothesis 


]

---

.pull-left[
Alternatively, we can perform analysis of variance using `lm()` and `anova()`:


``` r
(lm_class &lt;- lm(m1 ~ exam, data = classdata))
#&gt; 
#&gt; Call:
#&gt; lm(formula = m1 ~ exam, data = classdata)
#&gt; 
#&gt; Coefficients:
#&gt; (Intercept)        examB        examC  
#&gt;      75.103       -3.140        3.838
anova(lm_class) |&gt; tidy() |&gt; kable(digits=c(0, 0, 0, 0, 3, 3))
```



|term      |  df| sumsq| meansq| statistic| p.value|
|:---------|---:|-----:|------:|---------:|-------:|
|exam      |   2|  1290|    645|     3.484|   0.033|
|Residuals | 161| 29810|    185|        NA|      NA|



* `df`: degrees of freedom `\(df_1=k-1\)` and `\(df_2=n-k\)`
* `sumsq`: SSG (top) and SSE (bottom)
* `meansq`: MSG (top) and MSE (bottom)
* `statistic`: F statistic: `\(F = \frac{MSG}{MSE}\)`
* `p.value`: p-value for the F statistic
]
--
.pull-right[
Is this p-value valid? Need to check conditions:

- Independence: if data comes from simple random sample, this holds. For students we aren't sure, so this might present problems, but let's assume it's OK
- Approximate normality - when sample size is large and no extreme outliers, then this is ok
- Approximately constant variance - each group has approximately the same variance

&lt;img src="lec22_files/figure-html/unnamed-chunk-12-1.png" width="396" style="display: block; margin: auto;" /&gt;

* Thus, we can use to reject `\(H_0\)`, which we do because it is smaller than 0.05

&lt;!-- - **Independence.** If the data are a simple random sample, this condition can be assumed to be --&gt;
&lt;!-- satisfied. For processes and experiments, carefully consider whether the data may be independent --&gt;
&lt;!-- (e.g., no pairing). For example, in the MLB data, the data were not sampled. However, there --&gt;
&lt;!-- are not obvious reasons why independence would not hold for most or all observations. --&gt;
&lt;!-- - **Approximately normal.** As with one- and two-sample testing for means, the normality as- --&gt;
&lt;!-- sumption is especially important when the sample size is quite small when it is ironically diﬀicult --&gt;
&lt;!-- to check for non-normality. A histogram of the observations from each group is shown in Figure 22.8.  --&gt;
&lt;!-- Since each of the groups we are considering have relatively large sample sizes, what --&gt;
&lt;!-- we are looking for are major outliers. None are apparent, so this conditions is reasonably met. --&gt;
&lt;!-- - **Constant variance.** The last assumption is that the variance in the groups is about equal from --&gt;
&lt;!-- one group to the next. This assumption can be checked by examining side-by-side box plots of --&gt;
&lt;!-- the outcomes across the groups, as in Figure 22.2. In this case, the variability is similar in the --&gt;
&lt;!-- four groups but not identical. We see in Table 22.3 that the standard deviation does not vary --&gt;
&lt;!-- much from one group to the next. --&gt;

&lt;!-- the observations are independent within and between groups, --&gt;
&lt;!-- the responses within each group are nearly normal, and --&gt;
&lt;!-- the variability across the groups is about equal. --&gt;
]

---

.pull-left[
### Example: Batting in MLB
* Let's see whether batting performance of baseball players differs according to position
  - Outfielder (OF)
  - Infielder (OF)
  - Catcher (C)
* Dataset: 429 Major League Baseball (MLB) players from 2018, each &gt;= 100 at bats
* Does the *on-base percentage* (OBP) differ across these 3 groups?

* Some variables and descriptions:


```
#&gt; # A tibble: 4 × 2
#&gt;   variable col1                                       
#&gt;   &lt;chr&gt;    &lt;chr&gt;                                      
#&gt; 1 name     Player name                                
#&gt; 2 team     abbreviated name of the player's team      
#&gt; 3 position player's primary field position (OF, IF, C)
#&gt; 4 OBP      On-base percentage
```
]

.pull-right[

* First few rows:
&lt;table class="table table-striped table-condensed" style="color: black; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; name &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; team &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; position &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; OBP &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Abreu, J &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; CWS &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; IF &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.325 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Acuna Jr., R &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; ATL &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; OF &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.366 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Adames, W &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TB &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; IF &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.348 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Adams, M &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; STL &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; IF &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.309 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;



* `position` has three levels:
    
    ``` r
    unique(mlb_players_18$position)
    #&gt; [1] OF IF C 
    #&gt; Levels: OF IF C
    ```

Null and alternative hypotheses:

- `\(H_0\)`: the OBP for these three groups (outfielders, in-fielders, and catchers) is the same; `$$\mu_{OF} = \mu_{IF} = \mu_C$$`
- `\(H_A\)`: there is some difference among these three groups: `\(\mu_{OF} \neq \mu_{IF}\)`, `\(\mu_{IF} \neq \mu_C\)`, or `\(\mu_{OF} \neq \mu_C\)`
]

---
.pull-left[
#### ANOVA analysis

First, we need to check the conditions for F statistic / ANOVA analysis to hold

Conditions for F statistic/ANOVA analysis

- Independence: if data comes from simple random sample, this holds.  For MLB we aren't sure, so this might present problems, but let's assume it's OK
- Approximate normality - when sample size is large and no extreme outliers, then this is ok
- Approximately constant variance - variance within each group is approximately the same across groups
]
.pull-right[
&lt;img src="lec22_files/figure-html/unnamed-chunk-16-1.png" width="432" style="display: block; margin: auto;" /&gt;
* Does appear to be approximately normal, no extreme outliers
* We see that variability across the groups is quite similar
* So our F statistic analysis can proceed

]

---

.pull-left[

To do analysis of variance, we use `lm()` and `anova()`:

``` r
(mod &lt;- lm(OBP~position, data=mlb_players_18))
#&gt; 
#&gt; Call:
#&gt; lm(formula = OBP ~ position, data = mlb_players_18)
#&gt; 
#&gt; Coefficients:
#&gt; (Intercept)   positionIF    positionC  
#&gt;    0.319819    -0.001433    -0.017881

anova(mod) |&gt; 
    tidy() |&gt; 
    kable(digits=c(0,0,3,4,2,3))
```



|term      |  df| sumsq| meansq| statistic| p.value|
|:---------|---:|-----:|------:|---------:|-------:|
|position  |   2| 0.016| 0.0080|      5.08|   0.007|
|Residuals | 426| 0.674| 0.0016|        NA|      NA|



&lt;!-- * Let's again look at the MLB data (note we are using a modified version of the `mlb_players_18` dataset) --&gt;
&lt;!-- ```{r} --&gt;
&lt;!-- #| echo: false --&gt;
&lt;!-- mlb_players_18 |&gt; --&gt;
&lt;!--   arrange(name) |&gt;  --&gt;
&lt;!--   select(name, team, position, OBP) |&gt; --&gt;
&lt;!--   slice_head(n = 4) |&gt; --&gt;
&lt;!--   kbl(linesep = "", booktabs = TRUE, align = "lllrrrrrr") |&gt; --&gt;
&lt;!--   kable_styling(bootstrap_options = c("striped", "condensed"),  --&gt;
&lt;!--                 latex_options = c("striped", "hold_position"), full_width = TRUE) --&gt;
&lt;!-- ``` --&gt;


]

.pull-right[

How to read ANOVA output table?

* `df`: degrees of freedom `\(df_1=k-1\)` and `\(df_2=n-k\)`
* `sumsq`: SSG (top) and SSE (bottom)
* `meansq`: MSG (top) and MSE (bottom)
* `statistic`: F statistic: `\(F = \frac{MSG}{MSE}\)`
* `p.value`: p-value for the F statistic
    * p-value is smaller than 0.05, so we can reject the null hypothesis


Can derive this entire tibble by using just `df` and `sumsq` (and `pf()` to calc p-value from the statistic)

* `meansq`: `sumsq` divided by `df`
* `statistic`: quotient of the two `meansq` values
* For `p.value`, can use `pf`:
    
    ``` r
    1 - pf(5.077, df1 = 2, df2 = 426)
    #&gt; [1] 0.006621471
    ```
]

---

.pull-left[
Can derive this entire tibble by using just `df` and `sumsq` (and `pf()` to calc p-value from the statistic)

* `meansq`: `sumsq` divided by `df`
* `statistic`: quotient of the two `meansq` values
* For `p.value`, can use `pf`:
    
    ``` r
    1 - pf(statistic, df1 = df1, df2 = df2)
    ```
    
]

.pull-right[
Let's try it


|term      |  df| sumsq|meansq |statistic |p.value |
|:---------|---:|-----:|:------|:---------|:-------|
|position  |   2| 0.016|X      |X         |X       |
|Residuals | 426| 0.674|X      |NA        |NA      |


]

---

.pull-left[
### Practice 
* IMS 22.9(a, b)
* IMS 22.9c
* IMS 22.12(a,b)
* IMS 22.12c
* IMS 22.13(a,b)
* Take 3 minutes to think about the problem, discuss with your neighbors
* I'll call on one of you and ask what your thoughts are for how to approach the problem
* Not expecting you to have the right answer!  Just want to hear how you approach the problem, then help guide you through thinking about the next steps 
    
]

.pull-right[

]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
